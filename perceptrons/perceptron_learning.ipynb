{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Learning Algorithm (Binary Classifier)\n",
    "\n",
    "### Modification History\n",
    "\\>\\>\\> ZJ Zhang (Jan 23th, 2017) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Given $N$ input vectors with $D$ dimensions as training data, with each noted as $\\boldsymbol{x_{i}}$ and known labels of $l_{i}$ (binary values of $-1$ or $1$), I will build a perceptron that the output of each $\\boldsymbol{x_{i}}$ is exactly its corresponding label of $l_{i}$. Each vector $\\boldsymbol{x_{i}}$ could be expressed as\n",
    "\n",
    "$$\n",
    "\\boldsymbol{x_{i}} = (x_{i,1}, x_{i,2}, ..., x_{i,D})\n",
    "$$\n",
    "with each element termed $x_{i,j}$ ($j=1,2,...,D$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "Training data are created by prior knowledge. I assume there are $N$ vectors (or points) serving as training data, randomly distributed within a $D$-dimensional sphere with a radius of $R$. Then I assign them labels based on a linear boundary, described by \n",
    "$$\n",
    "p_{0} + p_{1}x_{1} + p_{2}x_{2} + ... + p_{D}x_{D} = 0 \\quad \\Rightarrow \\quad \\boldsymbol{m_{j}}\\boldsymbol{x_{j}}=0\n",
    "$$\n",
    "where,\n",
    "$$\n",
    "\\boldsymbol{p} = (p_{0}, p_{1}, p_{2}, ..., p_{D}) \\\\\n",
    "\\boldsymbol{x} = (1, x_{1}, x_{2}, ..., x_{D})\n",
    "$$\n",
    "**If an vector point is above the boundary, then I assign a label of $1$, otherwise (i.e., below or right on the boundary), I assign a label of $-1$.**\n",
    "\n",
    "Here I assume all data are uniformly distributed in the hypersphere. In addition, the boundary parameters $\\boldsymbol{p}$ are generated randomly within $[p_{\\rm min}, p_{\\rm max}]$ with a dimension of $D+1$. The following parameters are defiend by the user: $N$, $D$, $R$, $p_{\\rm bound} = [p_{\\rm min}, p_{\\rm max}]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# metric of the training data\n",
    "Nd = 1000 # number of vectors/points\n",
    "Dd = 2   # dimension\n",
    "Rd = 100  # radius of the hypersphere where all data are distributed\n",
    "p_bound = [-10, 10]  # extent of the boundary parameters\n",
    "\n",
    "# generate the prior boundary parameter p\n",
    "p_param = np.random.uniform(low=p_bound[0], high=p_bound[-1], size=Dd+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training data generation\n",
    "Train_Data = np.random.uniform(low=-Rd, high=Rd, size=(Nd,Dd+1))\n",
    "Train_Data[:,0] = 1.0  # append a 1.0 to the beginning of each vectors' coordinates\n",
    "# assign labels based on points' position compared to the prior boundary\n",
    "Train_boolLabel = np.sum(Train_Data*p_param, axis=1) > 0  # points located above the boundary have \"True\" with remaining have \"False\"\n",
    "Train_Label = 2 * Train_boolLabel - 1  # convert \"True\" and \"False\" to \"1\" and \"-1\", respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot the training data and the prior boundary - for 2D only\n",
    "if Dd==2:\n",
    "    # marker geometry\n",
    "    marker = 'o'\n",
    "    markersize = 10\n",
    "    markeredgewidth = 1\n",
    "    # colors\n",
    "    pos_color = 'goldenrod'\n",
    "    neg_color = 'lightgrey'\n",
    "    edgecolor = 'k'\n",
    "    # lines\n",
    "    marker_linestyle = 'None'\n",
    "    bound_linestyle = '-'\n",
    "    bound_linewdith = 4\n",
    "    prbound_color = 'blue'\n",
    "    # plot points with different labels\n",
    "    pos_id = np.where(Train_Label==1)[0]\n",
    "    plt.plot(Train_Data[pos_id,1], Train_Data[pos_id,2], marker=marker, \n",
    "             markersize=markersize, markerfacecolor=pos_color, markeredgecolor=edgecolor, \n",
    "             markeredgewidth=markeredgewidth, linestyle=marker_linestyle, label='label=1')\n",
    "    neg_id = np.where(Train_Label==-1)[0]\n",
    "    plt.plot(Train_Data[neg_id,1], Train_Data[neg_id,2], marker=marker, \n",
    "             markersize=markersize, markerfacecolor=neg_color, markeredgecolor=edgecolor, \n",
    "             markeredgewidth=markeredgewidth, linestyle=marker_linestyle, label=u'label=\\u22121')\n",
    "    # plot the prior boundary\n",
    "    x_bound = np.linspace(-Rd, Rd,2)\n",
    "    y_prbound = -1.0 * (p_param[0] + p_param[1]*x_bound) / p_param[2]\n",
    "    plt.plot(x_bound, y_prbound, color=prbound_color, linestyle=bound_linestyle, \n",
    "             linewidth=bound_linewdith, label='prior boundary')\n",
    "    # limits and label\n",
    "    plt.xlim([-Rd, Rd])\n",
    "    plt.ylim([-Rd, Rd])\n",
    "    # legend\n",
    "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=3, numpoints=1, mode=\"expand\", borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Algorithm\n",
    "The perceptron learning is actually to find the (linear) boundary that separate the vectors/points with two labels, given the training data. The whole algorithm include the following steps:\n",
    "\n",
    "1) Initialize a boundary parameter $\\boldsymbol{w}$, weights.\n",
    "\n",
    "2) For misclassified examples (e.g., $\\boldsymbol{x_{j}}$ whose $l_{j} \\neq y_{j}$), compute the classifier output ($y_{j}$) and update the weights based on $\\boldsymbol{w} += c (l_{j} - y_{j}) \\boldsymbol{x_{j}}$, where $c$ is the learning rate.\n",
    "\n",
    "3) Iterate among all of the training data until the output classification of all data match their own labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build up a perceptron - Proof of Concept\n",
    "# learning rate\n",
    "learn_rate = np.pi\n",
    "# initialize the boundary parameter\n",
    "w_bound = [-100, 100]\n",
    "w_param = np.random.uniform(low=w_bound[0], high=w_bound[-1], size=Dd+1)\n",
    "# success number\n",
    "success_num = 0\n",
    "# index of scanning the training data\n",
    "index = 0\n",
    "while success_num<Nd:\n",
    "    # decide if the current data has correct model-predicted label\n",
    "    Model_boolLabel_cur = np.sum(w_param * Train_Data[index]) > 0\n",
    "    Model_Label_cur = 2 * Model_boolLabel_cur - 1\n",
    "    if Model_Label_cur==Train_Label[index]:\n",
    "        success_num += 1\n",
    "    else:\n",
    "        sucess_num = 0\n",
    "        w_param += learn_rate * (Train_Label[index] - Model_Label_cur) * Train_Data[index]\n",
    "    index = (index+1)%Nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare the model-predicted boundary with the prior boundary - for 2D only\n",
    "if Dd==2:\n",
    "    # marker geometry\n",
    "    marker = 'o'\n",
    "    markersize = 10\n",
    "    markeredgewidth = 1\n",
    "    # colors\n",
    "    pos_color = 'goldenrod'\n",
    "    neg_color = 'lightgrey'\n",
    "    edgecolor = 'k'\n",
    "    # lines\n",
    "    marker_linestyle = 'None'\n",
    "    bound_linestyle = '-'\n",
    "    bound_linewdith = 4\n",
    "    prbound_color = 'blue'\n",
    "    compbound_color = 'red'\n",
    "    # plot points with different labels\n",
    "    pos_id = np.where(Train_Label==1)[0]\n",
    "    plt.plot(Train_Data[pos_id,1], Train_Data[pos_id,2], marker=marker, \n",
    "             markersize=markersize, markerfacecolor=pos_color, markeredgecolor=edgecolor, \n",
    "             markeredgewidth=markeredgewidth, linestyle=marker_linestyle, label='label=1')\n",
    "    neg_id = np.where(Train_Label==-1)[0]\n",
    "    plt.plot(Train_Data[neg_id,1], Train_Data[neg_id,2], marker=marker, \n",
    "             markersize=markersize, markerfacecolor=neg_color, markeredgecolor=edgecolor, \n",
    "             markeredgewidth=markeredgewidth, linestyle=marker_linestyle, label=u'label=\\u22121')\n",
    "    # plot the prior boundary\n",
    "    x_bound = np.linspace(-Rd, Rd,2)\n",
    "    y_prbound = -1.0 * (p_param[0] + p_param[1]*x_bound) / p_param[2]\n",
    "    plt.plot(x_bound, y_prbound, color=prbound_color, linestyle=bound_linestyle, \n",
    "             linewidth=bound_linewdith, label='prior boundary')\n",
    "    # plot the model-predicted boundary\n",
    "    y_compbound = -1.0 * (w_param[0] + w_param[1]*x_bound) / w_param[2]\n",
    "    plt.plot(x_bound, y_compbound, color=compbound_color, linestyle=bound_linestyle, \n",
    "             linewidth=bound_linewdith, label='model-predicted boundary')\n",
    "    # limits and label\n",
    "    plt.xlim([-Rd, Rd])\n",
    "    plt.ylim([-Rd, Rd])\n",
    "    # legend\n",
    "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, numpoints=1, mode=\"expand\", borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigations\n",
    "Here I investigate the following few points:\n",
    "\n",
    "1) The maximum interation number $N_{\\rm iter,max}$ as a function of learning rate $R_{\\rm learn}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here I build up the perceptron again, by including more components\n",
    "# initialize the boundary parameter\n",
    "w_bound = [-100, 100]\n",
    "w_param = np.random.uniform(low=w_bound[0], high=w_bound[-1], size=Dd+1)\n",
    "# list of learning rates\n",
    "Rlearn = np.array([1.0e-4, 3.0e-4, 1.0e-3, 3.0e-3, 1.0e-2, 3.0e-2, 1.0e-1, 3.0e-1, \n",
    "                        1.0, 3.0, 10., 30., 1.0e2, 3.0e2, 1.0e3, 3.0e3, 1.0e4])\n",
    "# create an array to save the maximum iterations and the final weights\n",
    "MaxNiter = np.ones_like(Rlearn) * np.nan\n",
    "Weights = np.ones((len(Rlearn), Dd+1)) * np.nan\n",
    "for index_learn in range(0,len(Rlearn)):\n",
    "    # iteration step\n",
    "    N_iter = 0\n",
    "    # success number\n",
    "    success_num = 0\n",
    "    # index of scanning the training data\n",
    "    index = 0\n",
    "    while success_num<Nd:\n",
    "        # decide if the current data has correct model-predicted label\n",
    "        Model_boolLabel_cur = np.sum(w_param * Train_Data[index]) > 0\n",
    "        Model_Label_cur = 2 * Model_boolLabel_cur - 1\n",
    "        if Model_Label_cur==Train_Label[index]:\n",
    "            success_num += 1\n",
    "        else:\n",
    "            sucess_num = 0\n",
    "            w_param += Rlearn[index_learn] * (Train_Label[index] - Model_Label_cur) * Train_Data[index]\n",
    "        index = (index+1)%Nd\n",
    "        # update iteration number\n",
    "        N_iter += 1\n",
    "    # save the maximum iterations and final weights\n",
    "    MaxNiter[index_learn] = N_iter\n",
    "    Weights[index_learn] = w_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.log10(Rlearn), MaxNiter)\n",
    "plt.xlabel(r'log$_{10}$(Learning Rate)')\n",
    "plt.ylabel('The Maximum Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
